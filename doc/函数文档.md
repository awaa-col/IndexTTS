# 函数文档（IndexTTS 核心）

说明：本节仅列出“推理链条”相关的关键类/函数，统一给出用途、输入/输出张量形状、类型（离散/连续）。形状默认使用 `(B 批, T 时间, C/Dim 通道)` 或注明具体布局。

— GPT 统一语音模型（`indextts/gpt/model_v2.py::UnifiedVoice`）
- 用途：文本条件 + 语音条件下，生成梅尔离散 token（自回归），并可返回中间潜向量用于后续声学扩散。
- 关键参数（来自 `checkpoints/config.yaml[gpt]`）：`model_dim=1280, heads=20, layers=24, number_text_tokens=12000, number_mel_codes=8194, max_text_tokens=600, max_mel_tokens=1815`。
- `post_init_gpt2_config(use_deepspeed=False, kv_cache=False, half=False)`：
  - 用途：构造 `GPT2InferenceModel` 包装（HF GPT2Model + 自定义输入拼接）。
- `get_conditioning(speech_conditioning_input, cond_mel_lengths=None)`：
  - 输入：连续 mel 条件，`(B, n_mels=100, S)` 或 `(B,S,100)`（视具体编码器）；
  - 输出：`conds (B, L_c=32, D_model=1280)`（Perceiver 下采样/重采样）；连续。
- `get_emo_conditioning(emo_speech_conditioning_latent, emo_cond_lengths)`：
  - 输入：同上；
  - 输出：`emo_vec (B, D_model)`，经 `emovec_layer(1024→1280)`、`emo_layer(1280→1280)`；连续。
- `prepare_gpt_inputs(conds_latent, text_inputs)`：
  - 输入：`conds_latent (B, L_c, 1280)` 连续；`text_inputs (B, L_t)` 离散 token；
  - 输出：`fake_input_ids (B, L_c+L_t+1)`、`inputs_embeds (B, L_c+L_t+2, 1280)`、`attention_mask (B, L_c+L_t+1)`。
- `inference_speech(speech_condition, text_inputs, ...)`（v2 版）：
  - 输入：`speech_condition (B, 100, S)` 连续；`text_inputs (B, L_t)` 离散；（可选）`emo_vec (B,1280)` 连续；
  - 输出：`mel_codes (B, L_m)`，离散 token，取值范围 `[0, number_mel_codes-1]`；同时返回 `speech_conditioning_latent (B, 32, 1280)` 连续。
- `forward(..., return_latent=True)`：
  - 输入：`speech_conditioning_latent (B, 32, 1280)`、`text_inputs (B, L_t)`、`mel_codes (B, L_m)` 等；
  - 输出：`gpt_latent (B, L_m, 1280)` 连续（代码中名为 mel_logits，实为未过线性头的隐藏表示）。

— 语义编解码（`indextts/utils/maskgct_utils.py`）
- `build_semantic_model`：Wav2Vec2-BERT 模型；
  - `get_emb(input_features, attention_mask)`：输出 `feat (B, T_sem, 1024)` 连续；经 `(feat-mean)/std` 归一化。
- `build_semantic_codec`：`RepCodec` 语义量化器；
  - `semantic_codec.quantize(inputs)`：返回 `(codes, emb)`：
    - `codes`：离散，形如 `(B, T_code)` 或 `(B, Q, T_code)`（Q 为 codebook 数）；
    - `emb`：连续，`(B, T_code, 1024)`（用于作为连续条件/提示）。
  - `quantizer.vq2emb(codes)`：将离散 `codes` 映射为连续嵌入，输出 `(B, T_code, 1024)`。

— 长度调节器（`indextts/s2mel/modules/length_regulator.py::InterpolateRegulator`）
- 用途：将内容嵌入（连续或离散）对齐/插值到目标 mel 帧长度；可选多 codebook、F0 条件与向量量化。
- 关键参数（`checkpoints/config.yaml[s2mel.length_regulator]`）：`is_discrete=false, in_channels=1024, channels=512, sampling_ratios=[1,1,1,1]`。
- `forward(x, ylens, n_quantizers=None, f0=None)`：
  - 输入：
    - 连续：`x (B, T_src, 1024)`；
    - 目标长度：`ylens (B,)`，整数；
  - 输出：`out (B, T_tgt, 512)` 连续，`olens (B,)`；若启用 VQ 还会返回 `codes`（离散）。

— 条件流匹配 CFM（`indextts/s2mel/modules/flow_matching.py::CFM`）
- 用途：在条件 `mu`（语义/内容 + 提示）与随机噪声之间，用固定步 Euler 求解还原 mel 频谱。
- `inference(mu, x_lens, prompt, style, f0, n_timesteps, inference_cfg_rate)`：
  - 输入：
    - `mu (B, T_all, 512)` 连续（由“提示条件 512 + 生成条件 512”在时间维拼接而成）；
    - `x_lens (B,)` 目标 mel 帧数；
    - `prompt (B, 80, T_prompt)` 连续；
    - `style (B, 192)` 连续（CAMPPlus）；
  - 输出：`mel (B, 80, T_all)` 连续；随后常截去 `[: , : , T_prompt:]`。

— 声码器 BigVGAN（`indextts/s2mel/modules/bigvgan/bigvgan.py::BigVGAN`）
- 用途：将 mel 频谱（80 维）转换为时域波形。
- `forward(x)`：
  - 输入：`x (B, 80, T)` 连续；
  - 输出：`wav (B, 1, N_samples)` 连续（`tanh` 限幅在 [-1,1]）。

— 特征提取（`indextts/utils/feature_extractors.py::MelSpectrogramFeatures`）
- 用途：按 24 kHz、`n_fft=1024, hop=256, n_mels=100` 提取 mel；
- `forward(audio)`：输入 `audio (B, T_samples)`，输出 `mel (B, 100, T_frames)` 连续。

— 推理封装（`indextts/infer_v2.py::IndexTTS2.infer` 关键张量）
- 语义侧：
  - `spk_cond_emb = get_emb(...) → (B, T_sem, 1024)`；
  - `S_ref = semantic_codec.quantize(spk_cond_emb)[1] → (B, T_ref, 1024)`；
  - `prompt_condition = length_regulator(S_ref, ylens=T_ref_mel) → (B, T_ref_mel, 512)`；
- 文本→离散 mel token：
  - `codes = gpt.inference_speech(spk_cond_emb(100ch), text_tokens) → (B, L_m)` 离散；
  - `gpt_latent = gpt(..., return_latent=True) → (B, L_m, 1280)` 连续 → `gpt_layer(1280→1024)`；
  - `S_infer = quantizer.vq2emb(codes) → (B, L_m, 1024)` 连续；`S_infer += gpt_layer(gpt_latent)`；
  - `cond = length_regulator(S_infer, ylens=T_gen_mel) → (B, T_gen_mel, 512)`；
- 扩散还原 + 声码器：
  - `cat_condition = cat([prompt_condition, cond], dim=T) → (B, T_all, 512)`；
  - `vc_target = cfm.inference(cat_condition, ..., ref_mel(80×T_ref), style(192)) → (B, 80, T_all)`；
  - 裁剪 `vc_target[..., T_ref:]` → 目标语音 mel → `BigVGAN.forward` → `wav (B, 1, N)`。

— 其它（离散/连续汇总）
- 文本 token：离散；
- `gpt.mel_codes`：离散（8194 类，包括起止符 8192/8193）；
- 语义/内容嵌入、GPT 潜向量、长度调节器输出、CFM/BigVGAN 输入：连续；
- 语义/内容 codebook：离散；`vq2emb` 映射为连续 1024 维。
