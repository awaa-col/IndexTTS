# 项目文档（index-tts）

## 模块总览
- `indextts/gpt/`: 统一语音-文本建模（UnifiedVoice），含 GPT-2 编码器/解码器、推理包装 `GPT2InferenceModel`、条件编码器（Perceiver/Conformer）。
- `indextts/s2mel/`: 声学侧与声码器集合（HiFT、HiFiGAN、BigVGAN 子实现）、训练辅助（flow matching、length regulator、quantize 等）。
- `indextts/BigVGAN/`: NVIDIA BigVGAN 实现（生成器/判别器、AMPBlock、ECAPA_TDNN 说话人编码器、Snake/SnakeBeta 激活）。
- `indextts/vqvae/`: 离散 VAE（`DiscreteVAE`、`Quantize`）用于将连续表示离散化为 code indices。
- `indextts/utils/`: 工具（特征抽取、采样、检查点、通用层）。
- 推理入口：`indextts/infer.py`、`indextts/infer_v2.py`、`indextts/cli.py`、`webui.py`。

## 典型调用链
- 文本合成（GPT → 扩散 → 声码器，`indextts/infer_v2.py`）
  1) 参考语音 16k → `w2v-bert` → 语义特征 `spk_cond_emb (B, T_sem, 1024)`；量化器 `semantic_codec.quantize` 得 `S_ref (B, T_ref, 1024)`
  2) `length_regulator(S_ref, ylens=T_ref_mel)` → `prompt_condition (B, T_ref_mel, 512)`；CAMPPlus 提取 `style (B,192)`
  3) 文本→`gpt.inference_speech(spk_cond_emb(100ch), text_tokens)` → 离散 `codes (B, L_m)`；
     `gpt(..., return_latent=True)` → `gpt_latent (B, L_m, 1280)` → `gpt_layer` 降维到 1024
  4) `S_infer = vq2emb(codes) (B, L_m, 1024) + gpt_layer(gpt_latent)`；`length_regulator(S_infer, ylens=T_gen_mel)` → `cond (B, T_gen, 512)`
  5) `cat_condition = cat([prompt_condition, cond], dim=time)`；`cfm.inference(cat_condition, ref_mel, style)` → `mel (B,80,T_all)`
  6) 截去提示段 `mel[..., T_ref:]` → `BigVGAN.forward` → `wav (B,1,N)`

- 快速/旧版路径（`indextts/infer.py`）
  1) `MelSpectrogramFeatures`(24k/100mel) → `cond_mel (B,100,S)`
  2) `gpt.inference_speech(cond_mel, text)` → `codes`；`gpt(..., return_latent=True)` → `latent (B, L_m, D)`
  3) 直接 `BigVGAN(latent, cond_mel^T)`（该实现里 BigVGAN 接口为自定义两输入版本）→ `wav`

## 文件与职责
- `indextts/gpt/model.py` / `model_v2.py`: `UnifiedVoice` 主体；文本/梅尔双头、条件编码、推理包装；`prepare_gpt_inputs` 构造 KV-cache 友好的输入。
- `indextts/BigVGAN/bigvgan.py` 与 `indextts/s2mel/modules/bigvgan/bigvgan.py`: BigVGAN 生成器两份实现（接口略有差异）；前者含 ECAPA 说话人条件分支。
- `indextts/BigVGAN/models.py`: 旧版 BigVGAN（含判别器 MPD/MRD、loss 计算）；训练相关。
- `indextts/BigVGAN/ECAPA_TDNN.py`: 说话人表征抽取。
- `indextts/s2mel/modules/hifigan/generator.py`: HiFT/HiFiGAN 风格的生成器（源-滤波 + ISTFTNet）。
- `indextts/vqvae/xtts_dvae.py`: `DiscreteVAE` 与 `Quantize` 实现；1D/2D 通道可配；训练/推理路径。

## 关键数据流（缩写）
- 语音条件 → `ConditioningEncoder/Conformer` → `PerceiverResampler` → `conds`
- 文本 token → `Embedding + PosEmb` → `text_emb`
- `[conds|text]` → `GPT2` → `mel_codes` 或 `gpt_latent`
- `S_ref/S_infer (1024)` → `length_regulator`(→512) → `CFM(DiT)` 还原 mel(80)
- `mel` → 声码器（BigVGAN/HiFT/HiFiGAN）→ 波形

## 注意
- BigVGAN CUDA AMP kernel 仅限推理；训练不可用。
- `indextts/BigVGAN` 与 `indextts/s2mel/modules/bigvgan` 存在重复实现，建议统一封装一份以减少维护成本。
 - 语义编码/量化来自外部 MaskGCT 组件（RepCodec），输出 1024 维连续嵌入与离散 codes；本项目在推理中将其作为条件而非端到端训练。
